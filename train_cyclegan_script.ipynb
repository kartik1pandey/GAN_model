{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:46.913586Z","iopub.execute_input":"2025-05-28T11:05:46.914263Z","iopub.status.idle":"2025-05-28T11:05:47.174945Z","shell.execute_reply.started":"2025-05-28T11:05:46.914237Z","shell.execute_reply":"2025-05-28T11:05:47.174429Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install kaggle -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:47.176039Z","iopub.execute_input":"2025-05-28T11:05:47.176378Z","iopub.status.idle":"2025-05-28T11:05:50.868251Z","shell.execute_reply.started":"2025-05-28T11:05:47.176360Z","shell.execute_reply":"2025-05-28T11:05:50.867548Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport glob\nimport zipfile\nimport io\nimport subprocess\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:50.869396Z","iopub.execute_input":"2025-05-28T11:05:50.869671Z","iopub.status.idle":"2025-05-28T11:05:55.639870Z","shell.execute_reply.started":"2025-05-28T11:05:50.869634Z","shell.execute_reply":"2025-05-28T11:05:55.639198Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class MonetPhotoDataset(Dataset):\n    def __init__(self, monet_dir, photo_dir, transform=None):\n        self.monet_images = sorted(glob.glob(os.path.join(monet_dir, \"*.jpg\")))\n        self.photo_images = sorted(glob.glob(os.path.join(photo_dir, \"*.jpg\")))\n        self.transform = transform\n\n    def __len__(self):\n        return max(len(self.monet_images), len(self.photo_images))\n\n    def __getitem__(self, idx):\n        monet_idx = idx % len(self.monet_images)\n        photo_idx = idx % len(self.photo_images)\n        \n        monet_img = Image.open(self.monet_images[monet_idx]).convert('RGB')\n        photo_img = Image.open(self.photo_images[photo_idx]).convert('RGB')\n        \n        if self.transform:\n            monet_img = self.transform(monet_img)\n            photo_img = self.transform(photo_img)\n        \n        return {'monet': monet_img, 'photo': photo_img}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.641515Z","iopub.execute_input":"2025-05-28T11:05:55.641832Z","iopub.status.idle":"2025-05-28T11:05:55.647236Z","shell.execute_reply.started":"2025-05-28T11:05:55.641813Z","shell.execute_reply":"2025-05-28T11:05:55.646468Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        def conv_block(in_channels, out_channels, kernel_size=4, stride=2, padding=1, norm=True, relu=True):\n            layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=not norm)]\n            if norm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            if relu:\n                layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n        \n        self.model = nn.Sequential(\n            *conv_block(3, 64, norm=False),   \n            *conv_block(64, 128),             \n            *conv_block(128, 256),           \n            *conv_block(256, 512),            \n            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)  \n        )\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.648110Z","iopub.execute_input":"2025-05-28T11:05:55.648361Z","iopub.status.idle":"2025-05-28T11:05:55.668412Z","shell.execute_reply.started":"2025-05-28T11:05:55.648340Z","shell.execute_reply":"2025-05-28T11:05:55.667646Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_norm=True, use_relu=True):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=not use_norm)]\n    if use_norm:\n        layers.append(nn.InstanceNorm2d(out_channels))\n    if use_relu:\n        layers.append(nn.ReLU(inplace=True))\n    return nn.Sequential(*layers)\n\ndef upconv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1, output_padding=0, use_norm=True, use_relu=True):\n    layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding=output_padding, bias=not use_norm)]\n    if use_norm:\n        layers.append(nn.InstanceNorm2d(out_channels))\n    if use_relu:\n        layers.append(nn.ReLU(inplace=True))\n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.669160Z","iopub.execute_input":"2025-05-28T11:05:55.669402Z","iopub.status.idle":"2025-05-28T11:05:55.680415Z","shell.execute_reply.started":"2025-05-28T11:05:55.669382Z","shell.execute_reply":"2025-05-28T11:05:55.679681Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            conv_block(channels, channels, kernel_size=3, stride=1, padding=1, use_norm=True, use_relu=True),\n            conv_block(channels, channels, kernel_size=3, stride=1, padding=1, use_norm=True, use_relu=False)\n        )\n    \n    def forward(self, x):\n        return x + self.block(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.681048Z","iopub.execute_input":"2025-05-28T11:05:55.681267Z","iopub.status.idle":"2025-05-28T11:05:55.693782Z","shell.execute_reply.started":"2025-05-28T11:05:55.681247Z","shell.execute_reply":"2025-05-28T11:05:55.693140Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, num_residual_blocks=9):\n        super(Generator, self).__init__()\n        self.initial = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            conv_block(3, 64, kernel_size=7, stride=1, padding=0, use_norm=True, use_relu=True)\n        )\n        self.down1 = conv_block(64, 128, kernel_size=3, stride=2, padding=1, use_norm=True, use_relu=True)\n        self.down2 = conv_block(128, 256, kernel_size=3, stride=2, padding=1, use_norm=True, use_relu=True)\n        self.res_blocks = nn.Sequential(\n            *[ResidualBlock(256) for _ in range(num_residual_blocks)]\n        )\n        self.up1 = upconv_block(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, use_norm=True, use_relu=True)\n        self.up2 = upconv_block(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, use_norm=True, use_relu=True)\n        self.final = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=0),\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        x = self.initial(x)\n        x = self.down1(x)\n        x = self.down2(x)\n        x = self.res_blocks(x)\n        x = self.up1(x)\n        x = self.up2(x)\n        x = self.final(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.694498Z","iopub.execute_input":"2025-05-28T11:05:55.694710Z","iopub.status.idle":"2025-05-28T11:05:55.705934Z","shell.execute_reply.started":"2025-05-28T11:05:55.694691Z","shell.execute_reply":"2025-05-28T11:05:55.705306Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def save_images(images, output_dir, prefix, start_idx):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    zip_path = os.path.join(output_dir, 'images.zip')\n    with zipfile.ZipFile(zip_path, 'a', zipfile.ZIP_DEFLATED) as zf:\n        for i, img in enumerate(images):\n            img = (img * 0.5 + 0.5) * 255 \n            img = img.detach().permute(1, 2, 0).cpu().numpy().astype('uint8')  \n            pil_img = Image.fromarray(img)\n            img_buffer = io.BytesIO()\n            pil_img.save(img_buffer, format='JPEG')\n            zf.writestr(f'{prefix}_{start_idx + i}.jpg', img_buffer.getvalue())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.706683Z","iopub.execute_input":"2025-05-28T11:05:55.706973Z","iopub.status.idle":"2025-05-28T11:05:55.719960Z","shell.execute_reply.started":"2025-05-28T11:05:55.706952Z","shell.execute_reply":"2025-05-28T11:05:55.719258Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def train_cyclegan(monet_dir, photo_dir, output_dir, epochs=100, batch_size=1, lr=0.0002, beta1=0.5):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    dataset = MonetPhotoDataset(monet_dir, photo_dir, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    gen_photo_to_monet = Generator().to(device)\n    gen_monet_to_photo = Generator().to(device)\n    disc_monet = Discriminator().to(device)\n    disc_photo = Discriminator().to(device)\n    \n    optimizer_G = torch.optim.Adam(\n        list(gen_photo_to_monet.parameters()) + list(gen_monet_to_photo.parameters()),\n        lr=lr, betas=(beta1, 0.999)\n    )\n    optimizer_D_monet = torch.optim.Adam(disc_monet.parameters(), lr=lr, betas=(beta1, 0.999))\n    optimizer_D_photo = torch.optim.Adam(disc_photo.parameters(), lr=lr, betas=(beta1, 0.999))\n    \n    criterion_GAN = nn.MSELoss()\n    criterion_cycle = nn.L1Loss()\n    criterion_identity = nn.L1Loss()\n    \n    lambda_cycle = 10.0\n    lambda_identity = 5.0\n    for epoch in range(epochs):\n        for i, batch in enumerate(dataloader):\n            real_monet = batch['monet'].to(device)\n            real_photo = batch['photo'].to(device)\n            batch_size = real_monet.size(0)\n            \n            real_label = torch.ones(batch_size, 1, 16, 16).to(device)\n            fake_label = torch.zeros(batch_size, 1, 16, 16).to(device)\n            \n            optimizer_G.zero_grad()\n            \n            identity_monet = gen_photo_to_monet(real_monet)\n            identity_photo = gen_monet_to_photo(real_photo)\n            loss_identity = (criterion_identity(identity_monet, real_monet) + criterion_identity(identity_photo, real_photo)) * lambda_identity\n            \n            fake_monet = gen_photo_to_monet(real_photo)\n            fake_photo = gen_monet_to_photo(real_monet)\n            pred_fake_monet = disc_monet(fake_monet)\n            pred_fake_photo = disc_photo(fake_photo)\n            loss_GAN_monet = criterion_GAN(pred_fake_monet, real_label)\n            loss_GAN_photo = criterion_GAN(pred_fake_photo, real_label)\n            \n            cycled_photo = gen_monet_to_photo(fake_monet)\n            cycled_monet = gen_photo_to_monet(fake_photo)\n            loss_cycle = (criterion_cycle(cycled_photo, real_photo) + criterion_cycle(cycled_monet, real_monet)) * lambda_cycle\n            \n            loss_G = loss_GAN_monet + loss_GAN_photo + loss_cycle + loss_identity\n            loss_G.backward()\n            optimizer_G.step()\n            \n            optimizer_D_monet.zero_grad()\n            pred_real_monet = disc_monet(real_monet)\n            loss_D_real_monet = criterion_GAN(pred_real_monet, real_label)\n            pred_fake_monet = disc_monet(fake_monet.detach())\n            loss_D_fake_monet = criterion_GAN(pred_fake_monet, fake_label)\n            loss_D_monet = (loss_D_real_monet + loss_D_fake_monet) * 0.5\n            loss_D_monet.backward()\n            optimizer_D_monet.step()\n            \n            optimizer_D_photo.zero_grad()\n            pred_real_photo = disc_photo(real_photo)\n            loss_D_real_photo = criterion_GAN(pred_real_photo, real_label)\n            pred_fake_photo = disc_photo(fake_photo.detach())\n            loss_D_fake_photo = criterion_GAN(pred_fake_photo, fake_label)\n            loss_D_photo = (loss_D_real_photo + loss_D_fake_photo) * 0.5\n            loss_D_photo.backward()\n            optimizer_D_photo.step()\n            \n            if i % 100 == 0:\n                print(f\"Epoch [{epoch+1}/{epochs}] Batch [{i}/{len(dataloader)}] \"\n                      f\"Loss_G: {loss_G.item():.4f} Loss_D_monet: {loss_D_monet.item():.4f} Loss_D_photo: {loss_D_photo.item():.4f}\")\n                \n                save_images(fake_monet, output_dir, f'epoch_{epoch+1}_batch_{i}', i)\n    \n    torch.save(gen_photo_to_monet.state_dict(), os.path.join(output_dir, 'gen_photo_to_monet.pth'))\n    torch.save(gen_monet_to_photo.state_dict(), os.path.join(output_dir, 'gen_monet_to_photo.pth'))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:05:55.721973Z","iopub.execute_input":"2025-05-28T11:05:55.722203Z","iopub.status.idle":"2025-05-28T11:05:55.740548Z","shell.execute_reply.started":"2025-05-28T11:05:55.722185Z","shell.execute_reply":"2025-05-28T11:05:55.739918Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!mkdir -p /root/.config/kaggle\n!mv ./kaggle.json /root/.config/kaggle/kaggle.json\n!chmod 600 /root/.config/kaggle/kaggle.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def setup_kaggle_competition(competition_name=\"gan-getting-started\", download_dir=\"./data\"):\n    \"\"\"\n    Download and extract the Kaggle competition dataset using the Kaggle CLI.\n    Returns paths to monet_jpg and photo_jpg directories.\n    \"\"\"\n    try:\n        subprocess.run([\"kaggle\", \"--version\"], check=True, capture_output=True)\n    except subprocess.CalledProcessError:\n        raise RuntimeError(\"Kaggle CLI is not installed. Install it with 'pip install kaggle'.\")\n\n    kaggle_config_dir = os.path.expanduser(\"~/.kaggle\")\n    kaggle_root_config_dir = \"/root/.config/kaggle\"\n    if not os.path.exists(os.path.join(kaggle_config_dir, \"kaggle.json\")) and \\\n       not os.path.exists(os.path.join(kaggle_root_config_dir, \"kaggle.json\")) and \\\n       not (os.getenv(\"KAGGLE_USERNAME\") and os.getenv(\"KAGGLE_KEY\")):\n        raise RuntimeError(\n            \"Kaggle authentication failed. Ensure kaggle.json is in ~/.kaggle/ or /root/.config/kaggle/, \"\n            \"or set KAGGLE_USERNAME and KAGGLE_KEY environment variables. \"\n            \"See https://github.com/Kaggle/kaggle-api/ for setup instructions.\"\n        )\n\n    download_path = Path(download_dir)\n    download_path.mkdir(parents=True, exist_ok=True)\n\n    try:\n        result = subprocess.run(\n            [\"kaggle\", \"competitions\", \"download\", \"-c\", competition_name, \"-p\", str(download_path)],\n            check=True, capture_output=True, text=True\n        )\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to download competition dataset: {e.stderr}\")\n\n    zip_files = list(download_path.glob(\"*.zip\"))\n    if not zip_files:\n        raise FileNotFoundError(\"No zip file found in the download directory.\")\n    dataset_zip = zip_files[0] \n\n    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n        zip_ref.extractall(download_path)\n\n    monet_dir = download_path / \"monet_jpg\"\n    photo_dir = download_path / \"photo_jpg\"\n\n    if not monet_dir.exists():\n        raise FileNotFoundError(f\"Monet directory not found at {monet_dir}\")\n    if not photo_dir.exists():\n        raise FileNotFoundError(f\"Photo directory not found at {photo_dir}\")\n\n    return str(monet_dir), str(photo_dir)\n\ndef main():\n    output_dir = \"./generated_images\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    try:\n        monet_dir, photo_dir = setup_kaggle_competition()\n    except Exception as e:\n        print(f\"Error setting up dataset: {e}\")\n        return\n\n    try:\n        train_cyclegan(\n            monet_dir=monet_dir,\n            photo_dir=photo_dir,\n            output_dir=output_dir,\n            epochs=3,\n            batch_size=1,\n            lr=0.0002,\n            beta1=0.5\n        )\n        print(f\"Training completed. Generated images saved to {output_dir}\")\n    except Exception as e:\n        print(f\"Error during training: {e}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}